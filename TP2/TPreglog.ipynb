{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TP 2 : Régression logistique\n",
    "\n",
    "## 1 Régularisation de Tikhonov\n",
    "\n",
    "### 1.1 : Étude de la fonction objectif :\n",
    "\n",
    "**Calcul du gradient :**\n",
    "\n",
    "$\\frac{df_1}{dw_0} (w_0, w)= \\frac 1 n \\sum_{i=1}^n{\\frac{-y_i}{1+exp(y_i(x_i^T*w + w_0))}}$\n",
    "\n",
    "\n",
    "$\\frac{df_1}{dw} (w_0, w)= \\frac 1 n \\sum_{i=1}^n{\\frac{-y_i*x_i}{1+exp(y_i(x_i^T*w + w_0))}} + \\rho * w$\n",
    "\n",
    "**Calcul de la hessienne :**\n",
    "\n",
    "$H = \\frac 1 n * \\sum_i{\\frac{y_i^2}{(2cosh(y_i/2(x_i^T*w + w_0))^2}} * \\begin{bmatrix}1 \\\\ x_i \\end{bmatrix} \\begin{bmatrix}1 \\\\ x_i \\end{bmatrix}^T + \\begin{vmatrix} 0 & 0 \\\\ 0 & {\\rho * I_p} \\end{vmatrix}  $\n",
    "\n",
    "Montrons que $H$ est définie positive. Posons $a_i = \\frac{y_i}{\\sqrt n (2cosh(y_i/2(x_i^T*w + w_0))}$ et $v_i = \\begin{bmatrix}1 \\\\ x_i \\end{bmatrix}$, on a :\n",
    "\n",
    "$\\forall u \\in \\mathbb R^{p+1}, u^T H u = u^T \\begin{vmatrix} 0 & 0 \\\\ 0 & {\\rho * I_p} \\end{vmatrix} u + \\sum_i{(u^T a_i v_i) (v_i^T a_i u) }$\n",
    "\n",
    "* $u^T \\begin{vmatrix} 0 & 0 \\\\ 0 & {\\rho * I_p} \\end{vmatrix} u = \\begin{bmatrix} 0 & {\\rho \\sum_{i=2}^{p+1}{u_i}} & {...} & {\\rho \\sum_{i=2}^{p+1}{u_i}} \\end{bmatrix} \\begin{bmatrix} u_1 \\\\ ... \\\\ u_ {p+1} \\end{bmatrix} = \\rho (\\sum_{i=2}^{p+1}{u_i})^2 > 0$\n",
    "* $\\sum_i{(u^T a_i v_i) (v_i^T a_i u) } = \\sum_i{(u^T a_i v_i)^2 } > 0$\n",
    "\n",
    "Ainsi $ u^T H u > 0$. \n",
    "\n",
    "Et donc $f_1$ est convexe\n",
    "\n",
    "### 1.2 : Programmation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import check_grad\n",
    "\n",
    "def objective(w, X, Y, rho, verbose=False):\n",
    "    \"\"\" Renvoie les données numériques du problème\n",
    "    :param w: Le vecteur [w0 w] de l'énoncé. On attend une liste de longueur p+1.\n",
    "    :param X: La matrice des vecteurs lignes xi. On attend une matrice de dimension n lignes * p+1 colonnes.\n",
    "        La 1ère colonne est composée uniquement de 1.\n",
    "    :param Y: Le vecteur des yi. Liste de longueur n.\n",
    "    :param rho: Le paramètre de régularisation.\n",
    "    \n",
    "    :return: La valeur de la fonction, son gradient et sa hessienne.\"\"\"\n",
    "    assert (len(Y), len(w)) == X.shape, \"Erreur de dimensions\"\n",
    "    n = len(Y)\n",
    "    p = len(w) - 1\n",
    "    # Valeur de la fonction au point w :\n",
    "    val = rho/2 * np.linalg.norm(w, 2)**2\n",
    "    for i in range(n):\n",
    "        s = np.exp(-Y[i]*np.dot(X[i,:], w))\n",
    "        if verbose:\n",
    "            print(\"Étape %d, Val = %f\" % (i, val))\n",
    "            print(\"s:\", s)\n",
    "        val += 1/n*np.log(1 + s)\n",
    "    \n",
    "    # Gradient de la fonction au point w \n",
    "    grad = np.zeros(p+1)\n",
    "    grad[1:] = rho * w[1:]\n",
    "    for i in range(n):\n",
    "        grad += 1/n * (Y[i]*X[i])/(1 + np.exp(Y[i] * np.dot(X[i,:], w)))\n",
    "        \n",
    "    # Matrice hessienne :\n",
    "    hess = np.identity(p+1)*rho\n",
    "    hess[0,0] = 0\n",
    "    for i in range(n):\n",
    "        v = X[i,:][np.newaxis]\n",
    "        hess += 1/n * (Y[i] / (2*np.cosh(Y[i]/(2*np.dot(X[i,:], w)))))**2 * v.T.dot(v)\n",
    "    return val, grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Écart absolu | Écart relatif\n",
      "----------------------------\n",
      "     0.953   |   2.0%\n",
      "     0.965   |   0.4%\n",
      "     0.992   |   0.7%\n",
      "     0.913   |   1.0%\n",
      "     0.958   |   0.4%\n",
      "     0.908   |   1.3%\n",
      "     0.905   |   1.2%\n",
      "     0.932   |   0.7%\n",
      "     0.928   |   0.6%\n",
      "     0.807   |   2.3%\n"
     ]
    }
   ],
   "source": [
    "from cervicalcancerutils import load_cervical_cancer\n",
    "\n",
    "X,y = load_cervical_cancer(\"riskfactorscervicalcancer.csv\")\n",
    "(n, p) = X.shape\n",
    "\n",
    "# On rajoute une colonne de 1 à X :\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "# Affichage des erreurs sur le gradient :\n",
    "n_verif = 10 # Nombre de vérification à effectuer\n",
    "print(\"Écart absolu | Écart relatif\")\n",
    "print(\"----------------------------\")\n",
    "for i in range(n_verif):\n",
    "    rho = np.random.random()\n",
    "    w = np.random.random(p+1)\n",
    "    f = lambda w:objective(w, X, y, rho)[0]\n",
    "    grad_f = lambda w:objective(w, X, y, rho)[1]\n",
    "    err = check_grad(f, grad_f, w)\n",
    "    err_rel = err/np.linalg.norm(grad_f(w))\n",
    "    print(\"%10.3f   | %5.1f%%\" % (err, err_rel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1.3 : Méthode de Newton :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loic/.local/lib/python3.5/site-packages/ipykernel/__main__.py:36: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9247bc2acf47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mproceed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnorm_grad\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0moptimum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-9247bc2acf47>\u001b[0m in \u001b[0;36mnewton\u001b[0;34m(objective, start, epsilon, max_iter, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Itération %d, val = %f, ||grad|| = %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpoint\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mproceed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnorm_grad\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/.local/lib/python3.5/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/.local/lib/python3.5/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "def newton(objective, start, epsilon=0.1, max_iter=1000,verbose=False):\n",
    "    \"\"\" Renvoie le point qui minimise la fonction objectif.\n",
    "    :param objective: une fonction qui prend un vecteur et renvoie (valeur, gradient, hessienne) en ce point.\n",
    "    :param start: le point de départ\n",
    "    \n",
    "    :return: le point qui minimise la fonction.\n",
    "    \"\"\"\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    proceed = True\n",
    "    i = 1\n",
    "    point = start\n",
    "    while proceed:\n",
    "        val, grad, hess = objective(point)\n",
    "        norm_grad = np.linalg.norm(grad)\n",
    "        if verbose:\n",
    "            print(\"Itération %d, val = %f, ||grad|| = %f\" % (i, val, norm_grad))\n",
    "        point -= np.linalg.inv(hess).dot(grad)\n",
    "        i += 1\n",
    "        proceed = i <= max_iter and norm_grad < epsilon\n",
    "\n",
    "optimum = newton(lambda w:objective(w, X, y, rho), np.zeros_like(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
