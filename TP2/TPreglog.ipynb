{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TP 2 : Régression logistique\n",
    "\n",
    "## 1 Régularisation de Tikhonov\n",
    "\n",
    "### 1.1 : Étude de la fonction objectif :\n",
    "\n",
    "**Calcul du gradient :**\n",
    "\n",
    "$\\frac{df_1}{dw_0} (w_0, w)= \\frac 1 n \\sum_{i=1}^n{\\frac{-y_i}{1+exp(y_i(x_i^T*w + w_0))}}$\n",
    "\n",
    "\n",
    "$\\frac{df_1}{dw} (w_0, w)= \\frac 1 n \\sum_{i=1}^n{\\frac{-y_i*x_i}{1+exp(y_i(x_i^T*w + w_0))}} + \\rho * w$\n",
    "\n",
    "**Calcul de la hessienne :**\n",
    "\n",
    "$H = \\frac 1 n * \\sum_i{\\frac{y_i^2}{(2cosh(y_i/2(x_i^T*w + w_0))^2}} * \\begin{bmatrix}1 \\\\ x_i \\end{bmatrix} \\begin{bmatrix}1 \\\\ x_i \\end{bmatrix}^T + \\begin{vmatrix} 0 & 0 \\\\ 0 & {\\rho * I_p} \\end{vmatrix}  $\n",
    "\n",
    "Montrons que $H$ est définie positive. Posons $a_i = \\frac{y_i}{\\sqrt n (2cosh(y_i/2(x_i^T*w + w_0))}$ et $v_i = \\begin{bmatrix}1 \\\\ x_i \\end{bmatrix}$, on a :\n",
    "\n",
    "$\\forall u \\in \\mathbb R^{p+1}, u^T H u = u^T \\begin{vmatrix} 0 & 0 \\\\ 0 & {\\rho * I_p} \\end{vmatrix} u + \\sum_i{(u^T a_i v_i) (v_i^T a_i u) }$\n",
    "\n",
    "* $u^T \\begin{vmatrix} 0 & 0 \\\\ 0 & {\\rho * I_p} \\end{vmatrix} u = \\begin{bmatrix} 0 & {\\rho \\sum_{i=2}^{p+1}{u_i}} & {...} & {\\rho \\sum_{i=2}^{p+1}{u_i}} \\end{bmatrix} \\begin{bmatrix} u_1 \\\\ ... \\\\ u_ {p+1} \\end{bmatrix} = \\rho (\\sum_{i=2}^{p+1}{u_i})^2 > 0$\n",
    "* $\\sum_i{(u^T a_i v_i) (v_i^T a_i u) } = \\sum_i{(u^T a_i v_i)^2 } > 0$\n",
    "\n",
    "Ainsi $ u^T H u > 0$. \n",
    "\n",
    "Et donc $f_1$ est convexe\n",
    "\n",
    "### 1.2 : Programmation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(w) = 5.533369, attendu : 5.283369\n",
      "Écart entre la hessienne et la valeur attendue :\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import check_grad\n",
    "\n",
    "def objective(w, X, Y, rho, verbose=False):\n",
    "    \"\"\" Renvoie les données numériques du problème\n",
    "    :param w: Le vecteur [w0 w] de l'énoncé. On attend une liste de longueur p+1.\n",
    "    :param X: La matrice des vecteurs lignes xi. On attend une matrice de dimension n lignes * p+1 colonnes.\n",
    "        La 1ère colonne est composée uniquement de 1.\n",
    "    :param Y: Le vecteur des yi. Liste de longueur n.\n",
    "    :param rho: Le paramètre de régularisation.\n",
    "    \n",
    "    :return: La valeur de la fonction, son gradient et sa hessienne.\"\"\"\n",
    "    assert (len(Y), len(w)) == X.shape, \"Erreur de dimensions\"\n",
    "    n = len(Y)\n",
    "    p = len(w) - 1\n",
    "    # Valeur de la fonction au point w :\n",
    "    val = rho/2 * np.linalg.norm(w, 2)**2\n",
    "    for i in range(n):\n",
    "        s = np.exp(-Y[i]*np.dot(X[i,:], w))\n",
    "        if verbose:\n",
    "            print(\"Étape %d, Val = %f\" % (i, val))\n",
    "            print(\"s:\", s)\n",
    "        val += 1/n*np.log(1 + s)\n",
    "    \n",
    "    # Gradient de la fonction au point w \n",
    "    grad = np.zeros(p+1)\n",
    "    grad[1:] = rho * w[1:]\n",
    "    for i in range(n):\n",
    "        grad += 1/n * (Y[i]*X[i])/(1 + np.exp(Y[i] * np.dot(X[i,:], w)))\n",
    "        \n",
    "    # Matrice hessienne :\n",
    "    hess = np.identity(p+1)*rho\n",
    "    hess[0,0] = 0\n",
    "    for i in range(n):\n",
    "        v = X[i,:][np.newaxis]\n",
    "        hess += 1/n * (Y[i] / (2*np.cosh(Y[i]/(2*np.dot(X[i,:], w)))))**2 * v.T.dot(v)\n",
    "#         if verbose:\n",
    "#             print(\"v.T.dot(v):\")\n",
    "#             print(v.T.dot(v))\n",
    "#             print(\"np.dot(X[i,:], w) = %f\" % np.dot(X[i,:], w))\n",
    "#             print(\"(Y[i] / (2*np.cosh(Y[i]/(2*np.dot(X[i,:], w)))))**2 = %f\"% \n",
    "#                   (Y[i] / (2*np.cosh(Y[i]/(2*np.dot(X[i,:], w)))))**2)\n",
    "#             print(\"hess:\")\n",
    "#             print(hess)\n",
    "    return val, grad, hess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test unitaire :\n",
      "f(w) = 5.533369, attendu : 5.283369\n",
      "Écart entre la hessienne et la valeur attendue :\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n",
      "Pour le gradient, avec les données 'cervical_cancer' :\n",
      "Écart absolu | Écart relatif\n",
      "----------------------------\n",
      "     0.834   |   0.4%\n",
      "     0.891   |   0.4%\n",
      "     0.938   |   0.6%\n",
      "     0.913   |   3.5%\n",
      "     1.152   |   0.5%\n",
      "     0.870   |   0.5%\n",
      "     1.013   |   0.8%\n",
      "     0.924   |   2.3%\n",
      "     0.908   |   0.5%\n",
      "     0.950   |   0.5%\n"
     ]
    }
   ],
   "source": [
    "from cervicalcancerutils import load_cervical_cancer\n",
    "\n",
    "\n",
    "# Test unitaire :\n",
    "y_test = np.array([-1, 1])\n",
    "X_test = np.array([[1,0,1],[1,1,0]])\n",
    "w_test = np.array([1,2,3])\n",
    "rho_test = 1/2\n",
    "\n",
    "print(\"Test unitaire :\")\n",
    "# f(w) :\n",
    "val_expected = 1/2*(np.log(1+np.exp(4)) + np.log(1+np.exp(-3))) + rho_test/2 * 13\n",
    "# hessienne :\n",
    "a1 = 1/2 * (1/(2*np.cosh(-1/8)))**2\n",
    "a2 = 1/2 * (1/(2*np.cosh(1/6)))**2\n",
    "m1 = np.array([[1,0,1], [0,0,0], [1,0,1]])\n",
    "m2 = np.array([[1,1,0], [1,1,0], [0,0,0]])\n",
    "m3 = np.array([[0,0,0], [0,1,0], [0,0,1]]) * rho_test\n",
    "hess_expected = a1*m1 + a2*m2 + m3\n",
    "\n",
    "\n",
    "val, grad, hess = objective(w_test, X_test, y_test, rho_test, verbose=False)\n",
    "print(\"f(w) = %f, attendu : %f\" % (val, val_expected))\n",
    "print(\"Écart entre la hessienne et la valeur attendue :\")\n",
    "print(hess - hess_expected)\n",
    "\n",
    "X,y = load_cervical_cancer(\"riskfactorscervicalcancer.csv\")\n",
    "(n, p) = X.shape\n",
    "\n",
    "# On rajoute une colonne de 1 à X :\n",
    "X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "# Affichage des erreurs sur le gradient :\n",
    "n_verif = 10 # Nombre de vérification à effectuer\n",
    "print(\"Pour le gradient, avec les données 'cervical_cancer' :\")\n",
    "print(\"Écart absolu | Écart relatif\")\n",
    "print(\"----------------------------\")\n",
    "for i in range(n_verif):\n",
    "    rho = np.random.random()\n",
    "    w = np.random.random(p+1)\n",
    "    f = lambda w:objective(w, X, y, rho)[0]\n",
    "    grad_f = lambda w:objective(w, X, y, rho)[1]\n",
    "    err = check_grad(f, grad_f, w)\n",
    "    err_rel = err/np.linalg.norm(grad_f(w))\n",
    "    print(\"%10.3f   | %5.1f%%\" % (err, err_rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.08736545 -0.99515305 -1.00484695]\n",
      " [-0.99515305  1.80343922  0.19656078]\n",
      " [-1.00484695  0.19656078  1.80343922]]\n",
      "[[ 5.08736545 -0.99515305 -1.00484695]\n",
      " [-0.99515305  1.80343922  0.19656078]\n",
      " [-1.00484695  0.19656078  1.80343922]]\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.inv(hess_expected))\n",
    "print(np.linalg.inv(hess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1.3 : Méthode de Newton :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itération 1, val = 0.693147, ||grad|| = 0.348264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loic/.local/lib/python3.5/site-packages/ipykernel/__main__.py:36: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-e655db869b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mproceed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnorm_grad\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0moptimum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-52-e655db869b5b>\u001b[0m in \u001b[0;36mnewton\u001b[0;34m(objective, start, epsilon, max_iter, verbose)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Itération %d, val = %f, ||grad|| = %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpoint\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mproceed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnorm_grad\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/.local/lib/python3.5/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/.local/lib/python3.5/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "def newton(objective, start, epsilon=0.1, max_iter=1000,verbose=False):\n",
    "    \"\"\" Renvoie le point qui minimise la fonction objectif.\n",
    "    :param objective: une fonction qui prend un vecteur et renvoie (valeur, gradient, hessienne) en ce point.\n",
    "    :param start: le point de départ\n",
    "    \n",
    "    :return: le point qui minimise la fonction.\n",
    "    \"\"\"\n",
    "    \n",
    "    i = 1\n",
    "    \n",
    "    proceed = True\n",
    "    i = 1\n",
    "    point = start\n",
    "    while proceed:\n",
    "        val, grad, hess = objective(point)\n",
    "        norm_grad = np.linalg.norm(grad)\n",
    "        if verbose:\n",
    "            print(\"Itération %d, val = %f, ||grad|| = %f\" % (i, val, norm_grad))\n",
    "        point -= np.linalg.inv(hess).dot(grad)\n",
    "        i += 1\n",
    "        proceed = i <= max_iter and norm_grad < epsilon\n",
    "\n",
    "optimum = newton(lambda w:objective(w, X, y, rho), np.zeros_like(w), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loic/.local/lib/python3.5/site-packages/ipykernel/__main__.py:36: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "val, grad, hess = objective(np.zeros_like(w), X, y, 1/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69314718056\n",
      "[-0.01428571  0.02614069 -0.00519101 -0.00713406  0.03676745  0.02519034\n",
      "  0.04564283  0.01268279  0.04115343  0.08619172  0.07996712  0.06396583\n",
      "  0.10082943  0.10233987  0.09926846  0.09926846 -0.01338632  0.03557389\n",
      "  0.07747075 -0.03359756  0.10242157  0.03330453  0.03178166  0.10882475\n",
      "  0.03682732  0.10882475  0.09953978]\n",
      "[[ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.0047619  0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.0047619  0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.0047619  0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.0047619  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.0047619  0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.0047619\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.\n",
      "   0.0047619  0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.0047619  0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.0047619  0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.0047619  0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.0047619  0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.0047619  0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.0047619  0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.0047619\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.\n",
      "   0.0047619  0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.0047619  0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.0047619  0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.0047619  0.         0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.0047619  0.         0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.0047619  0.         0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.0047619  0.         0.\n",
      "   0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.0047619\n",
      "   0.         0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.\n",
      "   0.0047619  0.         0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.0047619  0.         0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.0047619  0.       ]\n",
      " [ 0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.         0.         0.         0.         0.         0.\n",
      "   0.         0.         0.0047619]]\n"
     ]
    }
   ],
   "source": [
    "print(val)\n",
    "print(grad)\n",
    "print(hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
