{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TP Recommendation\n",
    "Loïc Herbelot\n",
    "\n",
    "### Question 1.1 : Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "def load_movielens(filename, minidata=False):\n",
    "    \"\"\"\n",
    "    Cette fonction lit le fichier filename de la base de donnees\n",
    "    Movielens, par exemple \n",
    "    filename = '~/datasets/ml-100k/u.data'\n",
    "    Elle retourne \n",
    "    R : une matrice utilisateur-item contenant les scores\n",
    "    mask : une matrice valant 1 si il y a un score et 0 sinon\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.loadtxt(filename, dtype=int)\n",
    "\n",
    "    R = sparse.coo_matrix((data[:, 2], (data[:, 0]-1, data[:, 1]-1)),\n",
    "                          dtype=float)\n",
    "    R = R.toarray()  # not optimized for big data\n",
    "\n",
    "    # code la fonction 1_K\n",
    "    mask = sparse.coo_matrix((np.ones(data[:, 2].shape),\n",
    "                              (data[:, 0]-1, data[:, 1]-1)), dtype=bool )\n",
    "    mask = mask.toarray()  # not optimized for big data\n",
    "\n",
    "    if minidata is True:\n",
    "        R = R[0:100, 0:200].copy()\n",
    "        mask = mask[0:100, 0:200].copy()\n",
    "\n",
    "    return R, mask\n",
    "\n",
    "\n",
    "def objective(P, Q0, R, mask, rho):\n",
    "    \"\"\"\n",
    "    La fonction objectif du probleme simplifie.\n",
    "    Prend en entree \n",
    "    P : la variable matricielle de taille C x I\n",
    "    Q0 : une matrice de taille U x C\n",
    "    R : une matrice de taille U x I\n",
    "    mask : une matrice 0-1 de taille U x I\n",
    "    rho : un reel positif ou nul\n",
    "\n",
    "    Sorties :\n",
    "    val : la valeur de la fonction\n",
    "    grad_P : le gradient par rapport a P\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = (R - Q0.dot(P)) * mask\n",
    "\n",
    "    val = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q0 ** 2) + np.sum(P ** 2))\n",
    "\n",
    "    grad_P = -Q0.T.dot(tmp) + rho*P\n",
    "\n",
    "    return val, grad_P\n",
    "\n",
    "\n",
    "def total_objective(P, Q, R, mask, rho):\n",
    "    \"\"\"\n",
    "    La fonction objectif du probleme complet.\n",
    "    Prend en entree \n",
    "    P : la variable matricielle de taille C x I\n",
    "    Q : la variable matricielle de taille U x C\n",
    "    R : une matrice de taille U x I\n",
    "    mask : une matrice 0-1 de taille U x I\n",
    "    rho : un reel positif ou nul\n",
    "\n",
    "    Sorties :\n",
    "    val : la valeur de la fonction\n",
    "    grad_P : le gradient par rapport a P\n",
    "    grad_Q : le gradient par rapport a Q\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = (R - Q.dot(P)) * mask\n",
    "\n",
    "    val = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q ** 2) + np.sum(P ** 2))\n",
    "\n",
    "    grad_P = 0  # todo\n",
    "\n",
    "    grad_Q = 0  # todo\n",
    "\n",
    "    return val, grad_P, grad_Q\n",
    "\n",
    "\n",
    "def total_objective_vectorized(PQvec, R, mask, rho):\n",
    "    \"\"\"\n",
    "    Vectorisation de la fonction precedente de maniere a ne pas\n",
    "    recoder la fonction gradient\n",
    "    \"\"\"\n",
    "\n",
    "    # reconstruction de P et Q\n",
    "    n_items = R.shape[1]\n",
    "    n_users = R.shape[0]\n",
    "    F = PQvec.shape[0] / (n_items + n_users)\n",
    "    Pvec = PQvec[0:n_items*F]\n",
    "    Qvec = PQvec[n_items*F:]\n",
    "    P = np.reshape(Pvec, (F, n_items))\n",
    "    Q = np.reshape(Qvec, (n_users, F))\n",
    "\n",
    "    val, grad_P, grad_Q = total_objective(P, Q, R, mask, rho)\n",
    "    return val, np.concatenate([grad_P.ravel(), grad_Q.ravel()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de R: (943, 1682)\n",
      "Taille de mask: (943, 1682)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = \"ml-100k/u.data\"\n",
    "\n",
    "#sans \"minidata\"\n",
    "R, mask = load_movielens(filename)\n",
    "print(\"Taille de R:\", R.shape)\n",
    "print(\"Taille de mask:\", mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de R_mini: (100, 200)\n",
      "Taille de mask_mini: (100, 200)\n"
     ]
    }
   ],
   "source": [
    "#avec \"minidata\"\n",
    "R_mini, mask_mini = load_movielens(filename, minidata=True)\n",
    "print(\"Taille de R_mini:\", R_mini.shape)\n",
    "print(\"Taille de mask_mini:\", mask_mini.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fonction de `minidata` :\n",
    "Comme on peut le voir dans le code source, l'argument `minidata` sert à indiquer si l'on veut une plus petite partie des informations, seulement 100 lignes et 200 colonnes.\n",
    "\n",
    "### Question 1.2 : Informations sur les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu du fichier d'info : \n",
      "943 users\n",
      "1682 items\n",
      "100000 ratings\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"ml-100k/u.info\") as f:\n",
    "    print(\"Contenu du fichier d'info : \\n\"+ f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "On voit qu'on a donc :\n",
    " * 943 utilisateurs\n",
    " * 1682 films\n",
    " * Pour un total de 100 000 notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 1.3 : Étude de la fonction objectif\n",
    "\n",
    "Ici j'ai tracé la fonction avec deux variables :\n",
    "![Graphe de la fonction objectif avec deux variables](plot_objective_2_var.png)\n",
    "\n",
    "\n",
    "On voit donc que la fonction n'est pas convexe.\n",
    "\n",
    "Le gradient de f est :\n",
    "\n",
    "$\\nabla f(P,Q) = (Q^T (1_K ⋅ (QP-R)) + \\rho P, 1_K ⋅ (QP-R)P^T + \\rho Q)$\n",
    "\n",
    "Le gradient de $f$ n'est pas lipschitzien, car ses dérivées partielles ne sont pas bornées.\n",
    "\n",
    "Exemple en dimension 1 :\n",
    "$f(x,y) = \\frac 1 2 (r- xy)^2 + \\frac \\rho 2 (x^2 + y^2) $\n",
    "\n",
    "$\\frac{df}{dx}(x) = x(y^2 + \\rho) - yr$ et n'est pas bornée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 2.1 :\n",
    "\n",
    "La fonction $g$ est convexe.\n",
    "\n",
    "Son gradient vaut : $\\nabla g(P) = -{Q^0}^T(1_K ⋅ (R - Q^0*P)) + \\rho P $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 2.2 : Calcul du gradient de $g$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vérification sautée.\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import check_grad\n",
    "\n",
    "# Initialisation des variables :\n",
    "rho = 0.2\n",
    "P = np.random.random((7, 1682))*100\n",
    "\n",
    "# Fonctions utilisées pour la vérification du gradient :\n",
    "\n",
    "def g(P):\n",
    "    \"\"\" Renvoie la sortie de la fonction objectif.\n",
    "    :param P: un vecteur ligne de 7*1682 éléments\n",
    "    :return : la sortie de la fonction objectif.\"\"\"\n",
    "    P = P.reshape((7, 1682))\n",
    "    return objective(P, Q0, R, mask, rho)[0]\n",
    "\n",
    "def grad_g(P):\n",
    "    \"\"\"Renvoie le gradient de la fonction objectif au point P.\n",
    "    :param P: un vecteur ligne de 7*1682 éléments\n",
    "    :return: le gradient sous forme de vecteur ligne.\"\"\"\n",
    "    P = P.reshape((7, 1682))\n",
    "    return objective(P, Q0, R, mask, rho)[1].ravel()\n",
    "\n",
    "# Activer/Désactiver la vérification du gradient :\n",
    "verif = False # Choix de l'utilisateur\n",
    "if verif :\n",
    "    # Attention, calcul très long :\n",
    "    print(\"Erreur sur le gradient :\")\n",
    "    for i in range(1):\n",
    "        Q0 = np.random.random((943, 7))\n",
    "        P = np.random.random((7, 1682))\n",
    "        print(\"Vérification n°%d :\" % i)\n",
    "        print(check_grad(lambda P:objective(P.reshape((7, 1682)), Q0, R, mask, rho)[0],\n",
    "                         lambda P:objective(P.reshape((7, 1682)), Q0, R, mask, rho)[1].ravel(),\n",
    "                         P.ravel()))\n",
    "else :\n",
    "    print(\"Vérification sautée.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 2.3 : Gradient à pas constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def gradient(g, P0, gamma, epsilon, n_iter=1000):\n",
    "    \"\"\" Minimise une fonction objectif par la méthode du gradient à pas constant.\n",
    "    :param g:       La fonction à minimiser\n",
    "    :param P0:      Le point de départ\n",
    "    :param gamma:   Le pas\n",
    "    :param epsilon: Critère d'arrêt : norme du gradient inférieure à epsilon\n",
    "    :param n_iter:  Le nombre maximum d'itérations\n",
    "    \n",
    "    :return: Le point qui minimise la fonction, la valeur de la fonction en ce point, et son gradient\n",
    "    \"\"\"\n",
    "    #Q0 est la matrice des 7 vecteurs singuliers à gauche de R\n",
    "    # (|C| = 7)\n",
    "    rho = 0.2\n",
    "    Q0, s, vt = svds(R, min(7, min(R.shape)))\n",
    "    x = P0\n",
    "    grad = objective(x, Q0, R, mask, rho)[1]\n",
    "    i = 0\n",
    "#     L = rho + np.linalg.norm(Q0.T.dot(Q0), 'fro')\n",
    "#     gamma = 1/L\n",
    "    while i < n_iter and np.linalg.norm(grad, 'fro') > epsilon:\n",
    "        val, grad = objective(x, Q0, R, mask, rho)\n",
    "        if i%10 == 0:\n",
    "            print(\"Iteration n°%5d, g(x) = %E\" % (i, val))\n",
    "        x -= gamma * grad\n",
    "        i += 1\n",
    "    print(\"Valeur maximale du gradient en ce point : \",np.max(grad))\n",
    "    return x, val, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 2.4 : Démonstration de la fonction `gradient` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration n°    0, g(x) = 5.780278E+08\n",
      "Iteration n°   10, g(x) = 2.523856E+06\n",
      "Iteration n°   20, g(x) = 3.173443E+05\n",
      "Iteration n°   30, g(x) = 2.980205E+05\n",
      "Iteration n°   40, g(x) = 2.978292E+05\n",
      "Iteration n°   50, g(x) = 2.978272E+05\n",
      "Valeur maximale du gradient en ce point :  0.00336705411742\n",
      "Minimum trouvé : 2.978272E+05\n",
      "10 valeurs au hasard :\n",
      "g(P) = 6.783189E+05\n",
      "g(P) = 5.961358E+06\n",
      "g(P) = 6.261511E+10\n",
      "g(P) = 6.236840E+10\n",
      "g(P) = 6.044102E+10\n",
      "g(P) = 6.215197E+10\n",
      "g(P) = 5.998706E+06\n",
      "g(P) = 6.854912E+05\n",
      "g(P) = 6.636624E+05\n",
      "g(P) = 6.614186E+05\n"
     ]
    }
   ],
   "source": [
    "# Trouvons le P qui minimise g :\n",
    "x, val, grad = gradient(g, np.random.random((7, 1682))*1000, 1, 0.1, n_iter=1000)\n",
    "print(\"Minimum trouvé : %E\" % val)\n",
    "\n",
    "# Essayons 10 valeurs au hasard pour vérifier la pertinence du résultat :\n",
    "print(\"10 valeurs au hasard :\")\n",
    "rho = 0.2\n",
    "Q0, s, vt = svds(R, min(7, min(R.shape)))\n",
    "for i in range(10):\n",
    "    # J'évite de prendre des matrices \"proches\" de 0, \n",
    "    # sinon on ne pourrait pas voir comment se comporte g.\n",
    "    # Je multiplie une matrice \"random\" par 10^[un entier au hasard]\n",
    "    exp = np.random.randint(-1, 5)\n",
    "    P = np.random.random((7, 1682))*10**exp\n",
    "    rand_val = objective(P, Q0, R, mask, rho)[0]\n",
    "    if rand_val < val:\n",
    "        print(\"Nouveau minimum trouvé :\")\n",
    "    print(\"g(P) = %E\" % (rand_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Question 3.1 : Recherche linéaire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration n°    0, g(x) = 6.009949E+08\n",
      "Iteration n°   10, g(x) = 2.952142E+08\n",
      "Iteration n°   20, g(x) = 1.613289E+08\n",
      "Iteration n°   30, g(x) = 9.352069E+07\n",
      "Iteration n°   40, g(x) = 5.615438E+07\n",
      "Iteration n°   50, g(x) = 3.450660E+07\n",
      "Iteration n°   60, g(x) = 2.156385E+07\n",
      "Iteration n°   70, g(x) = 1.366078E+07\n",
      "Iteration n°   80, g(x) = 8.762728E+06\n",
      "Iteration n°   90, g(x) = 5.693684E+06\n",
      "Iteration n°  100, g(x) = 3.754568E+06\n",
      "Iteration n°  110, g(x) = 2.521342E+06\n",
      "Iteration n°  120, g(x) = 1.732921E+06\n",
      "Iteration n°  130, g(x) = 1.226702E+06\n",
      "Iteration n°  140, g(x) = 9.005132E+05\n",
      "Iteration n°  150, g(x) = 6.896940E+05\n",
      "Iteration n°  160, g(x) = 5.530874E+05\n",
      "Iteration n°  170, g(x) = 4.643715E+05\n",
      "Iteration n°  180, g(x) = 4.066448E+05\n",
      "Iteration n°  190, g(x) = 3.690182E+05\n",
      "Iteration n°  200, g(x) = 3.444556E+05\n",
      "Iteration n°  210, g(x) = 3.283994E+05\n",
      "Iteration n°  220, g(x) = 3.178910E+05\n",
      "Iteration n°  230, g(x) = 3.110059E+05\n",
      "Iteration n°  240, g(x) = 3.064904E+05\n",
      "Iteration n°  250, g(x) = 3.035261E+05\n",
      "Iteration n°  260, g(x) = 3.015786E+05\n",
      "Iteration n°  270, g(x) = 3.002982E+05\n",
      "Iteration n°  280, g(x) = 2.994557E+05\n",
      "Iteration n°  290, g(x) = 2.989010E+05\n",
      "Iteration n°  300, g(x) = 2.985356E+05\n",
      "Iteration n°  310, g(x) = 2.982948E+05\n",
      "Iteration n°  320, g(x) = 2.981359E+05\n",
      "Iteration n°  330, g(x) = 2.980311E+05\n",
      "Iteration n°  340, g(x) = 2.979620E+05\n",
      "Iteration n°  350, g(x) = 2.979163E+05\n",
      "Iteration n°  360, g(x) = 2.978861E+05\n",
      "Iteration n°  370, g(x) = 2.978661E+05\n",
      "Iteration n°  380, g(x) = 2.978530E+05\n",
      "Iteration n°  390, g(x) = 2.978442E+05\n",
      "Iteration n°  400, g(x) = 2.978385E+05\n",
      "Iteration n°  410, g(x) = 2.978346E+05\n",
      "Iteration n°  420, g(x) = 2.978321E+05\n",
      "Iteration n°  430, g(x) = 2.978304E+05\n",
      "Iteration n°  440, g(x) = 2.978293E+05\n",
      "Iteration n°  450, g(x) = 2.978286E+05\n",
      "Iteration n°  460, g(x) = 2.978281E+05\n",
      "Iteration n°  470, g(x) = 2.978278E+05\n",
      "Iteration n°  480, g(x) = 2.978276E+05\n",
      "Iteration n°  490, g(x) = 2.978274E+05\n",
      "Iteration n°  500, g(x) = 2.978273E+05\n",
      "Iteration n°  510, g(x) = 2.978273E+05\n",
      "Iteration n°  520, g(x) = 2.978272E+05\n",
      "Iteration n°  530, g(x) = 2.978272E+05\n",
      "Iteration n°  540, g(x) = 2.978272E+05\n",
      "Iteration n°  550, g(x) = 2.978272E+05\n",
      "Valeur maximale du gradient en ce point :  0.00328637882419\n",
      "Minimum trouvé : 2.978272E+05\n",
      "10 valeurs au hasard :\n",
      "g(P) = 6.869396E+05\n",
      "g(P) = 8.050641E+05\n",
      "g(P) = 5.653895E+08\n",
      "g(P) = 5.744490E+08\n",
      "g(P) = 5.692412E+10\n",
      "g(P) = 6.869997E+05\n",
      "g(P) = 5.751126E+08\n",
      "g(P) = 5.624694E+10\n",
      "g(P) = 5.724299E+08\n",
      "g(P) = 6.899423E+06\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def lin_gradient(g, P0, epsilon, n_iter=1000):\n",
    "    \"\"\" Minimise une fonction objectif par la méthode du gradient à pas constant.\n",
    "    :param g:       La fonction à minimiser\n",
    "    :param P0:      Le point de départ\n",
    "    :param epsilon: Critère d'arrêt : norme du gradient inférieure à epsilon\n",
    "    :param n_iter:  Le nombre maximum d'itérations\n",
    "    \n",
    "    :return: Le point qui minimise la fonction, la valeur de la fonction en ce point, et son gradient\n",
    "    \"\"\"\n",
    "    #Q0 est la matrice des 7 vecteurs singuliers à gauche de R\n",
    "    # (|C| = 7)\n",
    "    rho = 0.2\n",
    "    Q0, s, vt = svds(R, min(7, min(R.shape)))\n",
    "    x = P0\n",
    "    grad = objective(x, Q0, R, mask, rho)[1]\n",
    "    i = 0\n",
    "    gamma_values = np.linspace(0.1, 10, 100)\n",
    "#     L = rho + np.linalg.norm(Q0.T.dot(Q0), 'fro')\n",
    "#     gamma = 1/L\n",
    "    while i < n_iter and np.linalg.norm(grad, 'fro') > epsilon:\n",
    "        g = lambda x:objective(x, Q0, R, mask, rho)\n",
    "        val, grad = g(x)\n",
    "        # Affichage des résultats :\n",
    "        if i%10 == 0:\n",
    "            print(\"Iteration n°%5d, g(x) = %E\" % (i, val))\n",
    "        id_argmin = np.argmin(lambda gamma: g(x - gamma*grad))\n",
    "        x -= gamma_values[id_argmin] * grad\n",
    "        i += 1\n",
    "    print(\"Valeur maximale du gradient en ce point : \",np.max(grad))\n",
    "    return x, val, grad\n",
    "\n",
    "\n",
    "# Trouvons le P qui minimise g :\n",
    "x, val, grad = lin_gradient(g, np.random.random((7, 1682))*1000, 0.1, n_iter=1000)\n",
    "print(\"Minimum trouvé : %E\" % val)\n",
    "\n",
    "# Essayons 10 valeurs au hasard pour vérifier la pertinence du résultat :\n",
    "print(\"10 valeurs au hasard :\")\n",
    "rho = 0.2\n",
    "Q0, s, vt = svds(R, min(7, min(R.shape)))\n",
    "for i in range(10):\n",
    "    # J'évite de prendre des matrices \"proches\" de 0, \n",
    "    # sinon on ne pourrait pas voir comment se comporte g.\n",
    "    # Je multiplie une matrice \"random\" par 10^[un entier au hasard]\n",
    "    exp = np.random.randint(-1, 5)\n",
    "    P = np.random.random((7, 1682))*10**exp\n",
    "    rand_val = objective(P, Q0, R, mask, rho)[0]\n",
    "    if rand_val < val:\n",
    "        print(\"Nouveau minimum trouvé :\")\n",
    "    print(\"g(P) = %E\" % (rand_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
